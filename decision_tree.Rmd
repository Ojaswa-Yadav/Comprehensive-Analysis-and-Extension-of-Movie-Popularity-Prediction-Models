---
title: "Decision Tree"
output: pdf_document
---

# Imports
```{r}
library(tidyverse)
library(dplyr)
library(caret)
library(readxl)
library(ggplot2)
library(corrplot)
library(dplyr)
library(GGally)
library(e1071)
library(tree)

set.seed(100)
```

```{r}
data <- read_xlsx("2014 and 2015 CSM dataset_labeld.xlsx")

data[is.na(data) | data=="Inf" | data=="NaN"] = NA
colnames(data)[which(names(data) == "Aggregate Followers")] <- "AggregateFollowers"

#data$GrossLabelNum <- as.numeric(as.factor(data$GrossLabel))

#data$GrossLabelFac <- as.factor(data$GrossLabel)


label_gross = c("Average", "Block-Buster", "Flop", "Success")
label_rating = c("Average", "Excellent", "Good", "Poor")
# label_gross = c("Flop", "Average", "Success", "Block-Buster")
# data[data=="Flop"] = "1"
# data[data=="Average"] = "2"
# data[data=="Success"] = "3"
# data[data=="Block-Buster"] = "4"
# label_rating = c("Poor", "Average", "Good", "Excellent")
# data[data=="Poor"] = "1"
# data[data=="Average"] = "2"
# data[data=="Good"] = "3"
# data[data=="Excellent"] = "4"

# data$GrossLabel <- as.numeric(data$GrossLabel)
# data$RatingLabel <- as.numeric(data$RatingLabel)

data$GrossLabel <- as.factor(data$GrossLabel)
data$RatingLabel <- as.factor(data$RatingLabel)

train_size <- floor(0.8 * nrow(data))
train_index <- sample(seq_len(nrow(data)), size = train_size)

train_conv <- data[train_index, c("Genre", "Budget", "Screens", "Sequel")]
test_conv <- data[-train_index, c("Genre", "Budget", "Screens", "Sequel")]

train_social <- data[train_index, c("Sentiment", "Views", "Likes", "Dislikes", "Comments", "AggregateFollowers")]
test_social <- data[-train_index, c("Sentiment", "Views", "Likes", "Dislikes", "Comments", "AggregateFollowers")]

train_both <- cbind(train_conv, train_social)
test_both <- cbind(test_conv, test_social)

train_gross <- data[train_index, c("GrossLabel")]
test_gross <- data[-train_index, c("GrossLabel")]

train_rating <- data[train_index, c("RatingLabel")]
test_rating <- data[-train_index, c("RatingLabel")]

```

```{r}
tree_classification <- function(train_data, test_data, label) {
  model <- tree(as.formula(paste(label, "~ .")), data = train_data)
  
  predictions <- predict(model, test_data)
  
  predictions = max.col(predictions)
  
  return(predictions)
}


pred_gross_conv <- tree_classification(
  cbind(train_gross, train_conv), test_conv, "GrossLabel")

#train_gross$GrossLabel <- as.factor(train_gross$GrossLabel)
pred_gross_social <- tree_classification(
   cbind(train_gross, train_social), test_social, "GrossLabel")

pred_gross_both <- tree_classification(
  cbind(train_gross, train_both), test_both, "GrossLabel")

pred_rating_conv <- tree_classification(
  cbind(train_rating, train_conv), test_conv, "RatingLabel")

pred_rating_social <- tree_classification(
  cbind(train_rating, train_social), test_social, "RatingLabel")

pred_rating_both <- tree_classification(
  cbind(train_rating, train_both), test_both, "RatingLabel")

```

```{r}

to_label <- function(nums, labels) {
  label = nums
  for (i in 1:47) {
    label[i] = labels[nums[i]]
  }
  return(label)
}

test_gross_label = to_label(test_gross$GrossLabel, label_gross)

pred_gross_conv_label = to_label(pred_gross_conv, label_gross)
pred_gross_social_label = to_label(pred_gross_social, label_gross)
pred_gross_both_label = to_label(pred_gross_both, label_gross)


test_rating_label = to_label(test_rating$RatingLabel, label_rating)

pred_rating_conv_label = to_label(pred_rating_conv, label_rating)
pred_rating_social_label = to_label(pred_rating_social, label_rating)
pred_rating_both_label = to_label(pred_rating_both, label_rating)
```



```{r}
gross_levels <- levels(data$GrossLabel)
#gross_levels <- levels(factor(test_gross_label))
test_gross_factor <- factor(test_gross_label, levels = gross_levels)
pred_gross_conv_factor <- factor(pred_gross_conv_label, levels = gross_levels)
pred_gross_social_factor <- factor(pred_gross_social_label, levels = gross_levels)
pred_gross_both_factor <- factor(pred_gross_both_label, levels = gross_levels)

rating_levels <- levels(data$RatingLabel)
#rating_levels <- levels(factor(test_rating_label))
test_rating_factor <- factor(test_rating_label, levels = rating_levels)
pred_rating_conv_factor <- factor(pred_rating_conv_label, levels = rating_levels)
pred_rating_social_factor <- factor(pred_rating_social_label, levels = rating_levels)
pred_rating_both_factor <- factor(pred_rating_both_label, levels = rating_levels)

```

```{r}
plot_confusion_matrix <- function(cm, title) {
  # Convert the matrix to a data frame for plotting
  cm_df <- as.data.frame(cm)
  
  # Reshape the data frame from wide to long format
  cm_long <- reshape2::melt(cm_df, varnames = c("Predicted", "Actual"), value.name = "Frequency")
  
  # Plot the confusion matrix
  ggplot(data = cm_long, aes(x = Predicted, y = Actual, fill = Frequency)) +
    geom_tile(color = "white") +  # Use white lines to separate the tiles
    geom_text(aes(label = Frequency), vjust = 1) +  # Add text in each tile
    coord_fixed() + 
    scale_fill_gradient(low = "white", high = "steelblue") +  # Gradient color for the tiles
    labs(title = title, x = "Predicted", y = "Actual") +  # Labels for the plot
    theme_minimal() +  # Minimal theme
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis text for better readability
}

cm_gross_conv <- table(Predicted = pred_gross_conv_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_conv, "Confusion Matrix for GrossLabel\n(Conventional Features)")

cm_gross_social <- table(Predicted = pred_gross_social_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_social, "Confusion Matrix for GrossLabel\n(Social Media Features)")

cm_gross_both <- table(Predicted = pred_gross_both_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_both, "Confusion Matrix for GrossLabel\n(Full Feature Set)")

cm_rating_conv <- table(Predicted = pred_rating_conv_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_conv, "Confusion Matrix for RatingLabel\n(Conventional Features)")

cm_rating_social <- table(Predicted = pred_rating_social_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_social, "Confusion Matrix for RatingLabel\n(Social Media Features)")

cm_rating_both <- table(Predicted = pred_rating_both_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_both, "Confusion Matrix for RatingLabel\n(Full Feature Set)")

```




```{r}
calculate_metrics <- function(predictions, actual) {
  cm <- table(Predicted = predictions, Actual = actual)

  # Calculate overall accuracy
  accuracy <- sum(diag(cm)) / sum(cm)

  # Initialize vectors to store precision and recall for each class
  precision <- rep(NA, ncol(cm))
  recall <- rep(NA, nrow(cm))
  
  # Calculate precision and recall for each class
  for (i in 1:ncol(cm)) {
    if (sum(cm[, i]) != 0) {
      precision[i] <- cm[i, i] / sum(cm[, i])
    }
    if (sum(cm[i, ]) != 0) {
      recall[i] <- cm[i, i] / sum(cm[i, ])
    }
  }

  # Calculate F1 score
  f1 <- ifelse((precision + recall) != 0, 2 * (precision * recall) / (precision + recall), NA)

  mean_precision <- mean(precision, na.rm = TRUE)
  mean_recall <- mean(recall, na.rm = TRUE)
  mean_f1 <- mean(f1, na.rm = TRUE)

  return(data.frame(Accuracy = accuracy, Precision = mean_precision, Recall = mean_recall, F1 = mean_f1))
}

metrics_gross_conv <- calculate_metrics(pred_gross_conv_factor, test_gross_factor)# Print the metrics
metrics_gross_social <- calculate_metrics(pred_gross_social_factor, test_gross_factor)
metrics_gross_both <- calculate_metrics(pred_gross_both_factor, test_gross_factor)
metrics_rating_conv <- calculate_metrics(pred_rating_conv_factor, test_rating_factor)
metrics_rating_social <- calculate_metrics(pred_rating_social_factor, test_rating_factor)
metrics_rating_both <- calculate_metrics(pred_rating_both_factor, test_rating_factor)

```



```{r}

metrics <- rbind(
  cbind(Model = "GrossLabel - Conventional", metrics_gross_conv),
  cbind(Model = "GrossLabel - Social", metrics_gross_social),
  cbind(Model = "GrossLabel - Combined", metrics_gross_both),
  cbind(Model = "RatingLabel - Conventional", metrics_rating_conv),
  cbind(Model = "RatingLabel - Social", metrics_rating_social),
  cbind(Model = "RatingLabel - Combined", metrics_rating_both)
)

print(metrics)



metrics_df <- data.frame(
  Group = rep(c("GrossLabel", "RatingLabel"), each = 3),
  Model = c(
    "Conventional", "Social", "Combined",
    "Conventional", "Social", "Combined"
  ),
  Accuracy = c(
    metrics_gross_conv[1, "Accuracy"], 
    metrics_gross_social[1, "Accuracy"], 
    metrics_gross_both[1, "Accuracy"], 
    metrics_rating_conv[1, "Accuracy"], 
    metrics_rating_social[1, "Accuracy"], 
    metrics_rating_both[1, "Accuracy"]
  )
)

metrics_df$Model <- factor(metrics_df$Model, levels = c("Social", "Conventional", "Combined"))

dodge <- position_dodge(width = 0.9)
ggplot(metrics_df, aes(x = Group, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", position = dodge) +
  geom_text(aes(label = Model, y = 0.03), position = dodge, vjust = -1.1, angle=45, color = "white", size = 4) +
  scale_fill_manual(values = c("Social" = "blue3", "Conventional" = "red3", "Combined" = "green3")) +
  labs(title = "Model Accuracy Comparison", y = "Accuracy (%)", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",  
        panel.spacing = unit(1.5, "lines")) 
```

```{r}
model_gross_conv <- tree(GrossLabel~ ., data = cbind(train_gross, train_conv))
model_gross_social <- tree(GrossLabel~ ., data = cbind(train_gross, train_social))
model_gross_both <- tree(GrossLabel~ ., data = cbind(train_gross, train_both))
model_rating_conv <- tree(RatingLabel~ ., data = cbind(train_rating, train_conv))
model_rating_social <- tree(RatingLabel~ ., data = cbind(train_rating, train_social))
model_rating_both <- tree(RatingLabel~ ., data = cbind(train_rating, train_both))
```


```{r}
plot(model_gross_conv)
title(main = "Decission Tree for GrossLabel\n(Conventional Features)")
text(model_gross_conv)

plot(model_gross_social)
title(main = "Decission Tree for GrossLabel\n(Social Media Features)")
text(model_gross_social)

plot(model_gross_both)
title(main = "Decission Tree for GrossLabel\n(Full Feature Set)")
text(model_gross_both)

plot(model_rating_conv)
title(main = "Decission Tree for RatingLabel\n(Conventional Features)")
text(model_rating_conv)

plot(model_rating_social)
title(main = "Decission Tree for RatingLabel\n(Social Media Features)")
text(model_rating_social)

plot(model_rating_both)
title(main = "Decission Tree for RatingLabel\n(Full Feature Set)")
text(model_rating_both)

```



```{r}
my_tree = model_gross_conv
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for GrossLabel\n(Conventional Features)")
model_gross_conv_pruned = prune.tree(my_tree, best=3)

my_tree =model_gross_social
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for GrossLabel\n(Social Media Features)")

my_tree = model_gross_both
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for GrossLabel\n(Full Feature Set)")

my_tree = model_rating_conv
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for RatingLabel\n(Conventional Features)")

my_tree = model_rating_social
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for RatingLabel\n(Social Media Features)")

my_tree = model_rating_both
my_cv = cv.tree(my_tree, FUN=prune.tree)
plot(my_cv$size, my_cv$dev, type='b', xlab = "Tree Size", ylab = "cross-validated classification error rate")
title(main = "Optimal Decission Tree Size for RatingLabel\n(Full Feature Set)")

```



```{r}
pruned_model_gross_conv = prune.tree(model_gross_conv, best=5)
plot(pruned_model_gross_conv)
title(main = "Pruned Decission Tree for GrossLabel\n(Conventional Features)")
text(pruned_model_gross_conv)

pruned_model_gross_social = prune.tree(model_gross_social, best=5)
plot(pruned_model_gross_social)
title(main = "Pruned Decission Tree for GrossLabel\n(Social Media Features)")
text(pruned_model_gross_social)

pruned_model_gross_both = prune.tree(model_gross_both, best=5)
plot(pruned_model_gross_both)
title(main = "Pruned Decission Tree for GrossLabel\n(Full Feature Set)")
text(pruned_model_gross_both)

pruned_model_rating_conv = prune.tree(model_rating_conv, best=5)
plot(pruned_model_rating_conv)
title(main = "Pruned Decission Tree for RatingLabel\n(Conventional Features)")
text(pruned_model_rating_conv)

pruned_model_rating_social = prune.tree(model_rating_social, best=5)
plot(pruned_model_rating_social)
title(main = "Pruned Decission Tree for RatingLabel\n(Social Media Features)")
text(pruned_model_rating_social)

pruned_model_rating_both = prune.tree(model_rating_both, best=5)
plot(pruned_model_rating_both)
title(main = "Pruned Decission Tree for RatingLabel\n(Full Feature Set)")
text(pruned_model_rating_both)

```



```{r}
tree_classification <- function(train_data, test_data, model) {
  #model <- tree(as.formula(paste(label, "~ .")), data = train_data)
  
  predictions <- predict(model, test_data)
  
  predictions = max.col(predictions)
  
  return(predictions)
}


pruned_pred_gross_conv <- tree_classification(
  cbind(train_gross, train_conv), test_conv, pruned_model_gross_conv)

pruned_pred_gross_social <- tree_classification(
   cbind(train_gross, train_social), test_social, pruned_model_gross_social)

pruned_pred_gross_both <- tree_classification(
  cbind(train_gross, train_both), test_both, pruned_model_gross_both)

pruned_pred_rating_conv <- tree_classification(
  cbind(train_rating, train_conv), test_conv, pruned_model_rating_conv)

pruned_pred_rating_social <- tree_classification(
  cbind(train_rating, train_social), test_social, pruned_model_rating_social)

pruned_pred_rating_both <- tree_classification(
  cbind(train_rating, train_both), test_both, pruned_model_rating_both)

```


```{r}

to_label <- function(nums, labels) {
  label = nums
  for (i in 1:47) {
    label[i] = labels[nums[i]]
  }
  return(label)
}

test_gross_label = to_label(test_gross$GrossLabel, label_gross)

pruned_pred_gross_conv_label = to_label(pruned_pred_gross_conv, label_gross)
pruned_pred_gross_social_label = to_label(pruned_pred_gross_social, label_gross)
pruned_pred_gross_both_label = to_label(pruned_pred_gross_both, label_gross)


test_rating_label = to_label(test_rating$RatingLabel, label_rating)

pruned_pred_rating_conv_label = to_label(pruned_pred_rating_conv, label_rating)
pruned_pred_rating_social_label = to_label(pruned_pred_rating_social, label_rating)
pruned_pred_rating_both_label = to_label(pruned_pred_rating_both, label_rating)
```


```{r}
gross_levels <- levels(data$GrossLabel)
#gross_levels <- levels(factor(test_gross_label))
test_gross_factor <- factor(test_gross_label, levels = gross_levels)
pruned_pred_gross_conv_factor <- factor(pruned_pred_gross_conv_label, levels = gross_levels)
pruned_pred_gross_social_factor <- factor(pruned_pred_gross_social_label, levels = gross_levels)
pruned_pred_gross_both_factor <- factor(pruned_pred_gross_both_label, levels = gross_levels)

rating_levels <- levels(data$RatingLabel)
#rating_levels <- levels(factor(test_rating_label))
test_rating_factor <- factor(test_rating_label, levels = rating_levels)
pruned_pred_rating_conv_factor <- factor(pruned_pred_rating_conv_label, levels = rating_levels)
pruned_pred_rating_social_factor <- factor(pruned_pred_rating_social_label, levels = rating_levels)
pruned_pred_rating_both_factor <- factor(pruned_pred_rating_both_label, levels = rating_levels)

```


```{r}
plot_confusion_matrix <- function(cm, title) {
  # Convert the matrix to a data frame for plotting
  cm_df <- as.data.frame(cm)
  
  # Reshape the data frame from wide to long format
  cm_long <- reshape2::melt(cm_df, varnames = c("Predicted", "Actual"), value.name = "Frequency")
  
  # Plot the confusion matrix
  ggplot(data = cm_long, aes(x = Predicted, y = Actual, fill = Frequency)) +
    geom_tile(color = "white") +  # Use white lines to separate the tiles
    geom_text(aes(label = Frequency), vjust = 1) +  # Add text in each tile
    #coord_fixed() + 
    scale_fill_gradient(low = "white", high = "steelblue") +  # Gradient color for the tiles
    labs(title = title, x = "Predicted", y = "Actual") +  # Labels for the plot
    theme_minimal() +  # Minimal theme
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis text for better readability
}

cm_gross_conv <- table(Predicted = pruned_pred_gross_conv_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_conv, "Confusion Matrix for GrossLabel\n(Conventional Features)")

cm_gross_social <- table(Predicted = pruned_pred_gross_social_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_social, "Confusion Matrix for GrossLabel\n(Social Media Features)")

cm_gross_both <- table(Predicted = pruned_pred_gross_both_factor, Actual = test_gross_factor)
plot_confusion_matrix(cm_gross_both, "Confusion Matrix for GrossLabel\n(Full Feature Set)")

cm_rating_conv <- table(Predicted = pruned_pred_rating_conv_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_conv, "Confusion Matrix for RatingLabel\n(Conventional Features)")

cm_rating_social <- table(Predicted = pruned_pred_rating_social_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_social, "Confusion Matrix for RatingLabel\n(Social Media Features)")

cm_rating_both <- table(Predicted = pruned_pred_rating_both_factor, Actual = test_rating_factor)
plot_confusion_matrix(cm_rating_both, "Confusion Matrix for RatingLabel\n(Full Feature Set)")

```


```{r}
calculate_metrics <- function(predictions, actual) {
  cm <- table(Predicted = predictions, Actual = actual)

  # Calculate overall accuracy
  accuracy <- sum(diag(cm)) / sum(cm)

  # Initialize vectors to store precision and recall for each class
  precision <- rep(NA, ncol(cm))
  recall <- rep(NA, nrow(cm))
  
  # Calculate precision and recall for each class
  for (i in 1:ncol(cm)) {
    if (sum(cm[, i]) != 0) {
      precision[i] <- cm[i, i] / sum(cm[, i])
    }
    if (sum(cm[i, ]) != 0) {
      recall[i] <- cm[i, i] / sum(cm[i, ])
    }
  }

  # Calculate F1 score
  f1 <- ifelse((precision + recall) != 0, 2 * (precision * recall) / (precision + recall), NA)

  mean_precision <- mean(precision, na.rm = TRUE)
  mean_recall <- mean(recall, na.rm = TRUE)
  mean_f1 <- mean(f1, na.rm = TRUE)

  return(data.frame(Accuracy = accuracy, Precision = mean_precision, Recall = mean_recall, F1 = mean_f1))
}

pruned_metrics_gross_conv <- calculate_metrics(pruned_pred_gross_conv_factor, test_gross_factor)# Print the metrics
pruned_metrics_gross_social <- calculate_metrics(pruned_pred_gross_social_factor, test_gross_factor)
pruned_metrics_gross_both <- calculate_metrics(pruned_pred_gross_both_factor, test_gross_factor)
pruned_metrics_rating_conv <- calculate_metrics(pruned_pred_rating_conv_factor, test_rating_factor)
pruned_metrics_rating_social <- calculate_metrics(pruned_pred_rating_social_factor, test_rating_factor)
pruned_metrics_rating_both <- calculate_metrics(pruned_pred_rating_both_factor, test_rating_factor)

```


```{r}

pruned_metrics <- rbind(
  cbind(Model = "GrossLabel - Conventional", pruned_metrics_gross_conv),
  cbind(Model = "GrossLabel - Social", pruned_metrics_gross_social),
  cbind(Model = "GrossLabel - Combined", pruned_metrics_gross_both),
  cbind(Model = "RatingLabel - Conventional", pruned_metrics_rating_conv),
  cbind(Model = "RatingLabel - Social", pruned_metrics_rating_social),
  cbind(Model = "RatingLabel - Combined", pruned_metrics_rating_both)
)

print(pruned_metrics)



pruned_metrics_df <- data.frame(
  Group = rep(c("GrossLabel", "RatingLabel"), each = 3),
  Model = c(
    "Conventional", "Social", "Combined",
    "Conventional", "Social", "Combined"
  ),
  Accuracy = c(
    pruned_metrics_gross_conv[1, "Accuracy"], 
    pruned_metrics_gross_social[1, "Accuracy"], 
    pruned_metrics_gross_both[1, "Accuracy"], 
    pruned_metrics_rating_conv[1, "Accuracy"], 
    pruned_metrics_rating_social[1, "Accuracy"], 
    pruned_metrics_rating_both[1, "Accuracy"]
  )
)

pruned_metrics_df$Model <- factor(pruned_metrics_df$Model, levels = c("Social", "Conventional", "Combined"))

dodge <- position_dodge(width = 0.9)
ggplot(pruned_metrics_df, aes(x = Group, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", position = dodge) +
  geom_text(aes(label = Model, y = 0.03), position = dodge, vjust = -1.1, angle=45, color = "white", size = 4) +
  scale_fill_manual(values = c("Social" = "blue3", "Conventional" = "red3", "Combined" = "green3")) +
  labs(title = "Model Accuracy Comparison", y = "Accuracy (%)", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",  
        panel.spacing = unit(1.5, "lines")) 
```